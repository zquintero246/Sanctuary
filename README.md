
````markdown
# ðŸ§  Sanctuary

**Sanctuary** es un sistema conversacional emocional diseÃ±ado para escuchar, pensar y hablar como un acompaÃ±ante humano. No es solo un chatbot: es una voz con identidad. Inspirado en el concepto simbÃ³lico de *DAEM*, Sanctuary busca crear un vÃ­nculo Ã­ntimo y empÃ¡tico con el usuario, integrando tecnologÃ­as avanzadas de procesamiento de voz y lenguaje natural.

---

## âš™ï¸ Arquitectura General

```plaintext
[ Usuario habla ]
       â†“
[ STT - Whisper (TranscripciÃ³n) ]
       â†“
[ LLM - Qwen/Mistral (GeneraciÃ³n de respuesta) ]
       â†“
[ TTS - XTTS/Tacotron (SÃ­ntesis de voz) ]
       â†“
[ ReproducciÃ³n de audio ]
````

Cada componente estÃ¡ diseÃ±ado como un mÃ³dulo desacoplado, permitiendo su reemplazo sin afectar el resto del sistema. El flujo estÃ¡ orquestado por un pipeline central.

---

## ðŸš€ CÃ³mo ejecutar Sanctuary

### 1. Clonar el repositorio

```bash
git clone https://github.com/zquintero246/Sanctuary.git
cd Sanctuary
```

### 2. Crear entorno virtual e instalar dependencias

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

> AsegÃºrate de tener `ffmpeg` y `CUDA` configurados si planeas usar Whisper con aceleraciÃ³n por GPU.

### 3. Ejecutar test del sistema

```bash
python main.py
```

Esto procesarÃ¡ el archivo de prueba ubicado en:

```
/Services/sanctuary_stt/test_audios/audio_test2.mp4
```

---

## ðŸ§© Estructura del proyecto

```plaintext
Sanctuary/
â”œâ”€â”€ Services/
â”‚   â”œâ”€â”€ sanctuary_core/      # Coordinador del flujo general (pipeline)
â”‚   â”œâ”€â”€ xtts_tts/            # GeneraciÃ³n de voz (TTS)
â”‚   â”œâ”€â”€ whisper_stt/         # Reconocimiento de voz (STT)
â”œâ”€â”€ main.py                  # Script que ejecuta el pipeline completo
â”œâ”€â”€ clear_gpu.sh            # Limpieza opcional de VRAM (solo NVIDIA)
â”œâ”€â”€ requirements.txt        # Dependencias del proyecto
â”œâ”€â”€ README.md               # Este archivo
```

---



## ðŸ›  Roadmap inicial

* [ ] âœ… Estructura inicial del proyecto
* [ ] Finalizar y probar flujo STT â†’ LLM â†’ TTS
* [ ] Exponer el sistema como API REST o WebSocket
* [ ] Crear interfaz web bÃ¡sica para probar interacciones
* [ ] AÃ±adir persistencia de contexto conversacional (memoria)
* [ ] Implementar logging robusto y manejo de errores
* [ ] Soporte para mÃºltiples voces / identidades

---

## ðŸ“„ Licencia
Este proyecto estÃ¡ licenciado bajo los tÃ©rminos de la Licencia Apache 2.0.
Consulta el archivo LICENSE para mÃ¡s detalles.
---



